// Code generated by sqlc. DO NOT EDIT.
// versions:
//   sqlc v2.3.0-wicked-fork
// source: query.sql

package epoch_states

import (
	"context"
	"crypto/sha256"
	"encoding/hex"
	"encoding/json"
	"fmt"
	"sync"
	"time"

	"github.com/jackc/pgx/v5"
	"github.com/jackc/pgx/v5/pgtype"
	"github.com/rs/zerolog/log"
)

const getEpochState = `-- name: GetEpochState :one
SELECT epoch_number, block_number, minimum_weight, total_weight, threshold_weight, updated_at FROM epoch_states
WHERE epoch_number = $1
`

// -- cache: 168h
// -- timeout: 500ms
func (q *Queries) GetEpochState(ctx context.Context, epochNumber uint32) (*EpochState, error) {
	return _GetEpochState(ctx, q.AsReadOnly(), epochNumber)
}

func (q *ReadOnlyQueries) GetEpochState(ctx context.Context, epochNumber uint32) (*EpochState, error) {
	return _GetEpochState(ctx, q, epochNumber)
}

func _GetEpochState(ctx context.Context, q CacheQuerierConn, epochNumber uint32) (*EpochState, error) {
	qctx, cancel := context.WithTimeout(ctx, time.Millisecond*500)
	defer cancel()
	q.GetConn().CountIntent("epoch_states.GetEpochState")
	dbRead := func() (any, time.Duration, error) {
		cacheDuration := time.Duration(time.Millisecond * 604800000)
		row := q.GetConn().WQueryRow(qctx, "epoch_states.GetEpochState", getEpochState, epochNumber)
		var i *EpochState = new(EpochState)
		err := row.Scan(
			&i.EpochNumber,
			&i.BlockNumber,
			&i.MinimumWeight,
			&i.TotalWeight,
			&i.ThresholdWeight,
			&i.UpdatedAt,
		)
		if err == pgx.ErrNoRows {
			return (*EpochState)(nil), cacheDuration, nil
		}
		return i, cacheDuration, err
	}
	if q.GetCache() == nil {
		i, _, err := dbRead()
		return i.(*EpochState), err
	}

	var i *EpochState
	err := q.GetCache().GetWithTtl(qctx, "epoch_states:GetEpochState:"+hashIfLong(fmt.Sprintf("%+v", epochNumber)), &i, dbRead, false, false)
	if err != nil {
		return nil, err
	}

	return i, err
}

const getLatestEpochState = `-- name: GetLatestEpochState :one
SELECT epoch_number, block_number, minimum_weight, total_weight, threshold_weight, updated_at FROM epoch_states
ORDER BY epoch_number DESC
LIMIT 1
`

// -- cache: 1h
// -- timeout: 500ms
func (q *Queries) GetLatestEpochState(ctx context.Context) (*EpochState, error) {
	return _GetLatestEpochState(ctx, q.AsReadOnly())
}

func (q *ReadOnlyQueries) GetLatestEpochState(ctx context.Context) (*EpochState, error) {
	return _GetLatestEpochState(ctx, q)
}

func _GetLatestEpochState(ctx context.Context, q CacheQuerierConn) (*EpochState, error) {
	qctx, cancel := context.WithTimeout(ctx, time.Millisecond*500)
	defer cancel()
	q.GetConn().CountIntent("epoch_states.GetLatestEpochState")
	dbRead := func() (any, time.Duration, error) {
		cacheDuration := time.Duration(time.Millisecond * 3600000)
		row := q.GetConn().WQueryRow(qctx, "epoch_states.GetLatestEpochState", getLatestEpochState)
		var i *EpochState = new(EpochState)
		err := row.Scan(
			&i.EpochNumber,
			&i.BlockNumber,
			&i.MinimumWeight,
			&i.TotalWeight,
			&i.ThresholdWeight,
			&i.UpdatedAt,
		)
		if err == pgx.ErrNoRows {
			return (*EpochState)(nil), cacheDuration, nil
		}
		return i, cacheDuration, err
	}
	if q.GetCache() == nil {
		i, _, err := dbRead()
		return i.(*EpochState), err
	}

	var i *EpochState
	err := q.GetCache().GetWithTtl(qctx, "epoch_states:GetLatestEpochState:", &i, dbRead, false, false)
	if err != nil {
		return nil, err
	}

	return i, err
}

const listEpochStates = `-- name: ListEpochStates :many
SELECT epoch_number, block_number, minimum_weight, total_weight, threshold_weight, updated_at FROM epoch_states
ORDER BY epoch_number DESC
LIMIT $1
`

// -- cache: 168h
// -- timeout: 1s
func (q *Queries) ListEpochStates(ctx context.Context, limit int32) ([]EpochState, error) {
	return _ListEpochStates(ctx, q.AsReadOnly(), limit)
}

func (q *ReadOnlyQueries) ListEpochStates(ctx context.Context, limit int32) ([]EpochState, error) {
	return _ListEpochStates(ctx, q, limit)
}

func _ListEpochStates(ctx context.Context, q CacheQuerierConn, limit int32) ([]EpochState, error) {
	qctx, cancel := context.WithTimeout(ctx, time.Millisecond*1000)
	defer cancel()
	q.GetConn().CountIntent("epoch_states.ListEpochStates")
	dbRead := func() (any, time.Duration, error) {
		cacheDuration := time.Duration(time.Millisecond * 604800000)
		rows, err := q.GetConn().WQuery(qctx, "epoch_states.ListEpochStates", listEpochStates, limit)
		if err != nil {
			return []EpochState(nil), 0, err
		}
		defer rows.Close()
		var items []EpochState
		for rows.Next() {
			var i *EpochState = new(EpochState)
			if err := rows.Scan(
				&i.EpochNumber,
				&i.BlockNumber,
				&i.MinimumWeight,
				&i.TotalWeight,
				&i.ThresholdWeight,
				&i.UpdatedAt,
			); err != nil {
				return []EpochState(nil), 0, err
			}
			items = append(items, *i)
		}
		if err := rows.Err(); err != nil {
			return []EpochState(nil), 0, err
		}
		return items, cacheDuration, nil
	}
	if q.GetCache() == nil {
		items, _, err := dbRead()
		return items.([]EpochState), err
	}
	var items []EpochState
	err := q.GetCache().GetWithTtl(qctx, "epoch_states:ListEpochStates:"+hashIfLong(fmt.Sprintf("%+v", limit)), &items, dbRead, false, false)
	if err != nil {
		return nil, err
	}

	return items, err
}

const upsertEpochState = `-- name: UpsertEpochState :one
INSERT INTO epoch_states (
    epoch_number,
    block_number,
    minimum_weight,
    total_weight,
    threshold_weight,
    updated_at
) VALUES (
    $1, $2, $3, $4, $5, $6
)
ON CONFLICT (epoch_number) DO UPDATE
SET
    block_number = EXCLUDED.block_number,
    minimum_weight = EXCLUDED.minimum_weight,
    total_weight = EXCLUDED.total_weight,
    threshold_weight = EXCLUDED.threshold_weight,
    updated_at = EXCLUDED.updated_at
RETURNING epoch_number, block_number, minimum_weight, total_weight, threshold_weight, updated_at
`

type UpsertEpochStateParams struct {
	EpochNumber     uint32         `json:"epoch_number"`
	BlockNumber     uint64         `json:"block_number"`
	MinimumWeight   pgtype.Numeric `json:"minimum_weight"`
	TotalWeight     pgtype.Numeric `json:"total_weight"`
	ThresholdWeight pgtype.Numeric `json:"threshold_weight"`
	UpdatedAt       time.Time      `json:"updated_at"`
}

// -- invalidate: GetEpochState
// -- invalidate: GetLatestEpochState
// -- invalidate: ListEpochStates
// -- timeout: 500ms
func (q *Queries) UpsertEpochState(ctx context.Context, arg UpsertEpochStateParams, listEpochStates *int32) (*EpochState, error) {
	return _UpsertEpochState(ctx, q, arg, listEpochStates)
}

func _UpsertEpochState(ctx context.Context, q CacheWGConn, arg UpsertEpochStateParams, listEpochStates *int32) (*EpochState, error) {
	qctx, cancel := context.WithTimeout(ctx, time.Millisecond*500)
	defer cancel()
	row := q.GetConn().WQueryRow(qctx, "epoch_states.UpsertEpochState", upsertEpochState,
		arg.EpochNumber,
		arg.BlockNumber,
		arg.MinimumWeight,
		arg.TotalWeight,
		arg.ThresholdWeight,
		arg.UpdatedAt)
	var i *EpochState = new(EpochState)
	err := row.Scan(
		&i.EpochNumber,
		&i.BlockNumber,
		&i.MinimumWeight,
		&i.TotalWeight,
		&i.ThresholdWeight,
		&i.UpdatedAt,
	)
	if err == pgx.ErrNoRows {
		return (*EpochState)(nil), nil
	} else if err != nil {
		return nil, err
	}

	// invalidate
	_ = q.GetConn().PostExec(func() error {
		anyErr := make(chan error, 1)
		var wg sync.WaitGroup
		wg.Add(1)
		go func() {
			defer wg.Done()
			if listEpochStates != nil {
				key := "epoch_states:ListEpochStates:" + hashIfLong(fmt.Sprintf("%+v", (*listEpochStates)))
				err = q.GetCache().Invalidate(ctx, key)
				if err != nil {
					log.Ctx(ctx).Error().Err(err).Msgf(
						"Failed to invalidate: %s", key)
					anyErr <- err
				}
			}
		}()
		wg.Wait()
		close(anyErr)
		return <-anyErr
	})
	return i, err
}

//// auto generated functions

func (q *Queries) Dump(ctx context.Context, beforeDump ...BeforeDump) ([]byte, error) {
	sql := "SELECT epoch_number,block_number,minimum_weight,total_weight,threshold_weight,updated_at FROM \"epoch_states\" ORDER BY updated_at ASC;"
	rows, err := q.db.WQuery(ctx, "epoch_states.Dump", sql)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items []EpochState
	for rows.Next() {
		var v EpochState
		if err := rows.Scan(&v.EpochNumber, &v.BlockNumber, &v.MinimumWeight, &v.TotalWeight, &v.ThresholdWeight, &v.UpdatedAt); err != nil {
			return nil, err
		}
		for _, applyBeforeDump := range beforeDump {
			applyBeforeDump(&v)
		}
		items = append(items, v)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	bytes, err := json.MarshalIndent(items, "", "  ")
	if err != nil {
		return nil, err
	}
	return bytes, nil
}

func (q *Queries) Load(ctx context.Context, data []byte) error {
	sql := "INSERT INTO \"epoch_states\" (epoch_number,block_number,minimum_weight,total_weight,threshold_weight,updated_at) VALUES ($1,$2,$3,$4,$5,$6);"
	rows := make([]EpochState, 0)
	err := json.Unmarshal(data, &rows)
	if err != nil {
		return err
	}
	for _, row := range rows {
		_, err := q.db.WExec(ctx, "epoch_states.Load", sql, row.EpochNumber, row.BlockNumber, row.MinimumWeight, row.TotalWeight, row.ThresholdWeight, row.UpdatedAt)
		if err != nil {
			return err
		}
	}
	return nil
}

func hashIfLong(v string) string {
	if len(v) > 64 {
		hash := sha256.Sum256([]byte(v))
		return "h(" + hex.EncodeToString(hash[:]) + ")"
	}
	return v
}

func ptrStr[T any](v *T) string {
	if v == nil {
		return "<nil>"
	}
	return fmt.Sprintf("%+v", *v)
}

// eliminate unused error
var _ = log.Logger
var _ = fmt.Sprintf("")
var _ = time.Now()
var _ = json.RawMessage{}
var _ = sha256.Sum256(nil)
var _ = hex.EncodeToString(nil)
var _ = sync.WaitGroup{}
